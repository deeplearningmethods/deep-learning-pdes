{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e95d356",
   "metadata": {},
   "source": [
    "# Classical numerics and operator learning for multidimensional gradient independent heat PDEs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22086a39",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "We consider the semilinear heat PDE d dimensions:\n",
    "$$\n",
    "    \\partial_t u (t, x)\n",
    "=\n",
    "    \\nu (\\Delta_{x} u)(t, x) + f(u(t, x)),\n",
    "$$\n",
    "for $(t, x) \\in [0,T] \\times [0, S]^d$ with periodic boundary conditions.\n",
    "\n",
    "\n",
    "We want to approximate the map\n",
    "$$\n",
    "\\Phi(u(0, \\cdot)) = u(T, \\cdot).\n",
    "$$\n",
    "\n",
    "Problem parameters:  $T, S, \\nu \\in (0,\\infty)$, $f \\colon \\mathbb{R} \\to \\mathbb{R}$, and distribution of initial value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ffaa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from scipy.fft import fft, ifft, fftfreq, fftn, ifftn\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from ipywidgets import interact, IntSlider\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import torch\n",
    "import openpyxl\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "sys.path.insert(1, '../1_Modules')\n",
    "\n",
    "# Importing the modules\n",
    "import random_function_generators\n",
    "import ode_methods\n",
    "import training\n",
    "import training_samples_generators\n",
    "import operator_learning_models\n",
    "import utils\n",
    "import semilinear_heat_multi_d_classical_methods\n",
    "import evaluation_utils\n",
    "import PDE_operations\n",
    "import documentation_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading the modules\n",
    "importlib.reload(random_function_generators)\n",
    "importlib.reload(ode_methods)\n",
    "importlib.reload(training)\n",
    "importlib.reload(training_samples_generators)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(operator_learning_models)\n",
    "importlib.reload(semilinear_heat_multi_d_classical_methods)\n",
    "importlib.reload(evaluation_utils)\n",
    "importlib.reload(PDE_operations)\n",
    "importlib.reload(documentation_utils)\n",
    "\n",
    "\n",
    "from random_function_generators import *\n",
    "from ode_methods import *\n",
    "from training import *\n",
    "from training_samples_generators import *\n",
    "from operator_learning_models import *\n",
    "from utils import *\n",
    "from semilinear_heat_multi_d_classical_methods import *\n",
    "from evaluation_utils import *\n",
    "from PDE_operations import *\n",
    "from documentation_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = True\n",
    "\n",
    "#Problem setup\n",
    "###################################################\n",
    "T = 3.\n",
    "space_size = 1.\n",
    "laplace_factor = 0.002\n",
    "nonlin = lambda x :  - x * x * x + x\n",
    "nonlin_name = \"AllenCahn\"\n",
    "dim = 1\n",
    "\n",
    "# initial value\n",
    "var = 5000\n",
    "decay_rate = 2\n",
    "offset = np.power(var, 1/decay_rate)\n",
    "inner_decay = 1.\n",
    "start_var = 0.2\n",
    "initial_value_generator = RandnFourierSeriesGeneratorStartControl([var, decay_rate, offset, inner_decay, space_size, start_var, dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f97708b58b64c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discretization operations\n",
    "x_values = x_values_periodic\n",
    "reduce_dimension = lambda values, space_resolution_step: reduce_dimension_periodic(values, space_resolution_step, dim=dim)\n",
    "get_higher_nr_spacediscr = get_higher_nr_spacediscr_periodic\n",
    "create_boundary_values = create_boundary_values_periodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the PDE\n",
    "pde_name = f\"Semilinear_heat_{dim}-dimensional_T_{T}_space_size_{space_size}_laplace_factor_{laplace_factor}_nonlin_{nonlin_name}_var_{var}_decay_rate_{decay_rate}_offset_{offset}_inner_decay_{inner_decay}_start_var_{start_var}\"\n",
    "\n",
    "#Create folder for all outputs\n",
    "output_folder_dir = create_output_folder(pde_name)\n",
    "\n",
    "# Prepare df to store data\n",
    "methods_data = pd.DataFrame(columns=[\"nr_params\", \"training_time\", \"test_time\", \"L2_error\", \"done_trainsteps\", \"learning_rate_history\", \"batch_size_history\"])\n",
    "methods = {}\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4efd3f",
   "metadata": {},
   "source": [
    "### Create Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data = True \n",
    "data_load_folder = f\"Z Outputs/ZZ 2023-11-21 08h55m16s {pde_name}/\"\n",
    "\n",
    "#Nr of input points allowed to be used by methods\n",
    "nr_spacediscr = 64 if test_run else 64\n",
    "\n",
    "#Method for reference solutions for training of models\n",
    "reference_algorithm = lambda initial_values, nr_timesteps: periodic_semilinear_pde_spectral_lirk(initial_values, T, laplace_factor, nonlin, space_size, nr_timesteps, dim=dim)\n",
    "\n",
    "# Train set parameters \n",
    "# TODO: Choose something suitable here in dependence of the dimension\n",
    "train_space_resolution_step = 2 if test_run else 2\n",
    "train_nr_timesteps = 1000 if test_run else 1000\n",
    "nr_train_samples = 1 if test_run else (2**10 if dim==2 else 2**18)\n",
    "nr_validation_samples = 1 if test_run else (2**9 if dim == 2 else 2**14)\n",
    "\n",
    "test_space_resolution_step = 4 if test_run else 4\n",
    "test_nr_timesteps = 1400 if test_run else 1400\n",
    "nr_test_samples = 1 if test_run else (2**9 if dim == 2 else 2**14)\n",
    "\n",
    "only_save_rough = True\n",
    "\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "parameters = {\n",
    "    'T': T,\n",
    "    'space_size': space_size,\n",
    "    'laplace_factor': laplace_factor,\n",
    "    'var': var,\n",
    "    'dim': dim,\n",
    "    'decay_rate': decay_rate,\n",
    "    'offset': offset,\n",
    "    'inner_decay': inner_decay,\n",
    "    'nr_spacediscr': nr_spacediscr,\n",
    "    'train_space_resolution_step': train_space_resolution_step,\n",
    "    'train_nr_timesteps': train_nr_timesteps,\n",
    "    'nr_train_samples': nr_train_samples,\n",
    "    'nr_validation_samples': nr_validation_samples,\n",
    "    'test_space_resolution_step': test_space_resolution_step,\n",
    "    'nr_test_samples': nr_test_samples,\n",
    "    'test_nr_timesteps': test_nr_timesteps,\n",
    "    'reference_algorithm': reference_algorithm.__name__,\n",
    "    'only_save_rough': only_save_rough\n",
    "}\n",
    "\n",
    "# save parametesr\n",
    "with open(output_folder_dir + 'train_test_parameters.json', 'w') as fp:\n",
    "    json.dump(parameters, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1acc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce train and test data\n",
    "train_nr_spacediscr = get_higher_nr_spacediscr(nr_spacediscr, train_space_resolution_step)\n",
    "test_nr_spacediscr = get_higher_nr_spacediscr(nr_spacediscr, test_space_resolution_step)\n",
    "\n",
    "print(\"Generating train samples\")\n",
    "train_initial_values_fine, train_ref_sol_fine, train_initial_values_rough, train_ref_sol_rough = (\n",
    "    get_data(\n",
    "        initial_value_generator, reference_algorithm, \n",
    "        nr_train_samples, train_nr_spacediscr, train_nr_timesteps, \n",
    "        reduce_dimension, train_space_resolution_step, 'train', \n",
    "        output_folder_dir, generate_data, data_load_folder, parameters, only_save_rough\n",
    "    ))\n",
    "training_samples_generator = TrainingSamplesGeneratorFromSolutions(train_initial_values_rough, train_ref_sol_rough)\n",
    "\n",
    "print(\"Generating validation samples\")\n",
    "validation_initial_values_fine, validation_ref_sol_fine, validation_initial_values_rough, validation_ref_sol_rough = (\n",
    "    get_data(\n",
    "        initial_value_generator, reference_algorithm, \n",
    "        nr_validation_samples, test_nr_spacediscr, test_nr_timesteps, \n",
    "        reduce_dimension, test_space_resolution_step, 'validate', \n",
    "        output_folder_dir, generate_data, data_load_folder, parameters, only_save_rough\n",
    "    ))\n",
    "\n",
    "print(\"Generating test samples\")\n",
    "test_initial_values_fine, test_ref_sol_fine, test_initial_values_rough, test_ref_sol_rough = (\n",
    "    get_data(\n",
    "        initial_value_generator, reference_algorithm, \n",
    "        nr_test_samples, test_nr_spacediscr, test_nr_timesteps, \n",
    "        reduce_dimension, test_space_resolution_step, 'test', \n",
    "        output_folder_dir, generate_data, data_load_folder, parameters, only_save_rough\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12374485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some reference solutions\n",
    "plot_reference_solutions(train_initial_values_rough, train_ref_sol_rough, 1, dim, x_values, space_size, pde_name, output_folder_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc28d7",
   "metadata": {},
   "source": [
    "# Create models and methods to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35719afb1ff23e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer_class = torch.optim.Adam\n",
    "# Loss function\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97888c2b",
   "metadata": {},
   "source": [
    "### Operator learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d12feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check if the training hyperparameters are suitable for all dimensions \n",
    "\n",
    "# Training hyperparams\n",
    "OL_training_kwargs = {\n",
    "    \"max_trainsteps\": 1 if test_run else 100000,\n",
    "    \"initial_batchsize\": 2**6 if test_run else 2**7 if dim ==1 else 2**6,\n",
    "    \"max_batchsize\": 2**6 if test_run else 2**7 if dim ==1 else 2**6,\n",
    "    \"output_steps\": 400 if test_run else 400,\n",
    "    \"eval_steps\": 400 if test_run else 400,\n",
    "    \"improvement_tolerance\": 0.97 if test_run else 0.97,\n",
    "    \"initial_lr\": 0.001\n",
    "}\n",
    "nr_runs = 1 if test_run else (1 if dim == 2 else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff15fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN models\n",
    "ann_foldername = output_folder_dir + \"Results_ANN\"\n",
    "\n",
    "#ANN Parameters\n",
    "input_dim = nr_spacediscr**dim\n",
    "if dim == 1:\n",
    "    list_ann_params = [\n",
    "        [[input_dim, 2**8, 2**9, 2**8, input_dim]],\n",
    "        [[input_dim,  2**10, 2**12, 2**10, input_dim]],\n",
    "        [[input_dim, 2**10, 2**12, 2**13, 2**12, 2**10, input_dim]]\n",
    "    ]\n",
    "if dim > 1:\n",
    "    list_ann_params = [\n",
    "        [[input_dim, input_dim, input_dim, input_dim]],\n",
    "        [[input_dim, input_dim, 2 * input_dim, input_dim, input_dim]],\n",
    "        [[input_dim, input_dim, 4 * input_dim, 4 * input_dim, input_dim, input_dim]]\n",
    "    ]\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = ANNModel, \n",
    "    list_params = list_ann_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=None,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = ann_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da483dc41dc78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN perdiodic models\n",
    "CNNPeriodic_foldername = output_folder_dir + \"Results_Periodic CNN\"\n",
    "\n",
    "#CNN Parameters [channel_dims, kernel_sizes, dim]\n",
    "if dim == 1:\n",
    "    list_cnn_periodic_params = [\n",
    "        [[1, 50, 50, 1],[31, 31, 31], 1],\n",
    "        [[1, 50, 50, 50, 1],[21, 21, 21, 21], 1],\n",
    "        [[1, 50, 100, 100, 50, 1], [21, 21, 21, 21, 21], 1],\n",
    "    ]\n",
    "if dim == 3:\n",
    "    list_cnn_periodic_params = [\n",
    "        [[1, 10, 10, 10, 10, 10, 10, 10, 10, 1],[3, 3, 3, 3, 3, 3, 3, 3], dim],\n",
    "        [[1, 20, 20, 20, 20, 20, 20, 20, 20, 1],[3, 3, 3, 3, 3, 3, 3, 3], dim],\n",
    "        [[1, 20, 20, 20, 20, 20, 20, 20, 20, 1],[3, 3, 5, 5, 5, 5, 3, 3], dim]\n",
    "    ]\n",
    "if dim == 2:\n",
    "    list_cnn_periodic_params = [\n",
    "        [[1, 10, 10, 10, 10, 10, 10, 10, 10, 1],[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dim],\n",
    "        [[1, 10, 10, 10, 10, 10, 10, 10, 10, 1],[5, 5, 5, 5, 9, 11, 9, 5, 5, 5, 5], dim],\n",
    "        [[1, 15, 15, 15, 15, 15, 15, 15, 15, 1],[5, 5, 5, 5, 9, 11, 9, 5, 5, 5, 5], dim]\n",
    "    ]\n",
    "\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = CNNPeriodicnDModel, \n",
    "    list_params = list_cnn_periodic_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=None,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = CNNPeriodic_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a97bf921b260e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN simple enc dec models\n",
    "CNNEncDec_foldername = output_folder_dir + \"Results_Enc-Dec CNN\"\n",
    "\n",
    "#CNN Parameters [channel_dims, kernel_sizes, dim]\n",
    "if dim == 1:\n",
    "    list_cnn_enc_dec_params = [\n",
    "        # [[1, 16, 32, 64],[2, 4, 2], 1],\n",
    "        [[1, 4, 16, 32, 128], [4, 2, 2, 2], 1],\n",
    "        [[1, 4, 16, 32, 128, 256], [4, 2, 2, 2, 2], 1],\n",
    "        [[1, 8, 16, 32, 64, 128, 256],[2, 2, 2, 2, 2, 2], 1]\n",
    "    ]\n",
    "if dim == 3:\n",
    "    list_cnn_enc_dec_params = [\n",
    "        [[1, 100, 200, 400],[4, 4, 1], dim],\n",
    "        [[1, 100, 200, 400, 800], [2, 2, 4, 1], dim],\n",
    "        [[1, 100, 200, 400, 800, 1600], [2, 2, 2, 2, 1], dim],\n",
    "    ]\n",
    "if dim == 2:\n",
    "    list_cnn_enc_dec_params = [\n",
    "        [[1, 2**7, 2**8, 2**9, 2**10],[4, 2, 2, 1], dim],\n",
    "        [[1, 2**7, 2**8, 2**9, 2**10, 2**11], [4, 2, 2, 2, 1], dim],\n",
    "        [[1, 2**7, 2**8, 2**9, 2**10, 2**11, 2**12, 2**12], [2, 2, 2, 2, 2, 2, 1], dim],\n",
    "        \n",
    "    ]\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = CNNEncDec, \n",
    "    list_params = list_cnn_enc_dec_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=None,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = CNNEncDec_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96886618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNO models\n",
    "FNO_foldername = output_folder_dir + \"Results_FNO\"\n",
    "\n",
    "#list is [#modes, width, depth]\n",
    "list_fno_params = [\n",
    "    [min(16, nr_spacediscr), 20, 4, dim],\n",
    "    [min(16, nr_spacediscr), 30, 4, dim],\n",
    "    [min(16, nr_spacediscr), 30, 5, dim]\n",
    "]\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = FNOnDModel, \n",
    "    list_params = list_fno_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=None,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = FNO_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42be20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepONets\n",
    "DeepONet_foldername = output_folder_dir + \"Results_DeepONet\"\n",
    "\n",
    "eval_points = x_values(nr_spacediscr, space_size, dim)\n",
    "eval_points = [np.expand_dims(eval_points_dim, axis=dim) for eval_points_dim in eval_points]\n",
    "eval_points = torch.tensor(np.concatenate(eval_points, axis=dim))\n",
    "DeepONet_space_grid = eval_points.reshape(-1,dim)  # Need shape (nr_spacediscr, dim)\n",
    "\n",
    "# DeepOnet Parameters [trunk_architecture, branch_architecture, eval_points]\n",
    "if dim==1:\n",
    "    list_deeponet_params = [\n",
    "        [[nr_spacediscr**dim, 2**11, 2**10, 2**9, 2**8],[dim, 2**7, 2**8], DeepONet_space_grid],\n",
    "        [[nr_spacediscr**dim, 2**11, 2**11, 2**10, 2**9],[dim, 2**7, 2**8, 2**9], DeepONet_space_grid],\n",
    "        [[nr_spacediscr**dim, 2**12, 2**13, 2**12, 2**12, 2**11],[dim, 2**9, 2**10, 2**11], DeepONet_space_grid]\n",
    "    ]\n",
    "if dim==2:\n",
    "    list_deeponet_params = [\n",
    "        [[nr_spacediscr**dim, 2**11, 2**10, 2**9, 2**8],[dim, 2**7, 2**8], DeepONet_space_grid],\n",
    "        [[nr_spacediscr**dim, 2**11, 2**11, 2**10, 2**9],[dim, 2**7, 2**8, 2**9], DeepONet_space_grid],\n",
    "        [[nr_spacediscr**dim, 2**12, 2**13, 2**12, 2**12, 2**11],[dim, 2**9, 2**10, 2**11], DeepONet_space_grid]\n",
    "    ]\n",
    "if dim==3:\n",
    "        list_deeponet_params = [\n",
    "        [[nr_spacediscr**dim, int(nr_spacediscr**dim/2), int(nr_spacediscr**dim/4), 100],[dim, 50, 100], DeepONet_space_grid],\n",
    "        [[nr_spacediscr**dim, int(nr_spacediscr**dim/2), int(nr_spacediscr**dim/4), 500],[dim, 200, 350, 500], DeepONet_space_grid],\n",
    "        [[nr_spacediscr**dim, nr_spacediscr**dim, nr_spacediscr**dim, nr_spacediscr**dim, int(nr_spacediscr**dim/2)],[dim, 500, 1000, int(nr_spacediscr**dim/2)], DeepONet_space_grid]\n",
    "    ]    \n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = DeepONet, \n",
    "    list_params = list_deeponet_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=None,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = DeepONet_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40611f84",
   "metadata": {},
   "source": [
    "### Classical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c036f2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Discretization parameters\n",
    "nr_timesteps_fdm = [3, 5, 10, 15, 20, 25, 30] if test_run else ([70, 80, 90] if dim==3 else([20, 25, 30] if dim==2 else [4, 8, 16]))\n",
    "nr_timesteps_spe = [70, 80, 90] if dim==3 else([20, 25, 30] if dim==2 else [8, 16, 24])\n",
    "\n",
    "# Create FDM methods\n",
    "# if dim <= 2:\n",
    "#     for nr_timesteps in nr_timesteps_fdm:\n",
    "#         name = f\"FDM ({nr_timesteps} timesteps)\"\n",
    "#         methods[name] = lambda initial_values_rough, nr_timesteps=nr_timesteps: periodic_semilinear_pde_fdm_lirk(initial_values_rough, T, laplace_factor, nonlin, space_size, nr_timesteps, dim=dim)\n",
    "#         methods_data.at[name, \"training_time\"] = 0\n",
    "\n",
    "\n",
    "#Create all methods for the correponding timesteps\n",
    "for nr_timesteps in nr_timesteps_spe:\n",
    "    name = f\"Spectral ({nr_timesteps} Crank Nicolson timesteps)\"\n",
    "    methods[name] = lambda initial_values_rough, nr_timesteps=nr_timesteps: periodic_semilinear_pde_spectral_lirk(initial_values_rough, T, laplace_factor, nonlin, space_size, nr_timesteps, dim=dim)\n",
    "    methods_data.at[name, \"training_time\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f818038",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3514c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all the methods and create plots\n",
    "nr_of_eval_runs = 100 if test_run else 1000\n",
    "plot_histogram = False if test_run else True\n",
    "\n",
    "# method_categories = [\"ANN\", \"DeepONet\", \"Spectral\"]\n",
    "method_categories = [\"ANN\", \"Periodic CNN\", \"Enc.-Dec. CNN\", \"FNO\", \"DeepONet\", \"Spectral\"] + ([\"FDM\"] if dim<=2 else [])\n",
    "space_grid = x_values(nr_spacediscr, space_size, dim=dim)\n",
    "\n",
    "evaluate_and_plot(methods, \n",
    "                  methods_data, \n",
    "                  method_categories, \n",
    "                  test_initial_values_rough, \n",
    "                  test_ref_sol_rough, \n",
    "                  space_grid, \n",
    "                  space_size, \n",
    "                  output_folder_dir, \n",
    "                  pde_name, \n",
    "                  dim=dim, \n",
    "                  nr_of_eval_runs=nr_of_eval_runs, \n",
    "                  plot_histogram=plot_histogram,\n",
    "                  legend_loc=None,\n",
    "                  nr_of_plots=1 if test_run else 3\n",
    "                  )\n",
    "\n",
    "#Save all the data in an Excel sheet\n",
    "local_vars = locals()\n",
    "params_dict = {k: [v] for k, v in local_vars.items() if isinstance(v, (int, str, float)) and k[0] != '_'}\n",
    "save_excel_sheet(methods_data, params_dict, output_folder_dir + f\"Results_{pde_name}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0d28520b5aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_error_vs_comptime_plot(method_categories, output_folder_dir, pde_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_PDE_survey",
   "language": "python",
   "name": "venv_pde_survey"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
