{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0aab011",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Classical numerics and operator learning for Burgers' PDE with FDM and FEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba13c0e",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "We consider the periodic burgers equation in 1d:\n",
    "$$\n",
    "    \\partial_t u (t, x)\n",
    "=\n",
    "    \\nu (\\partial_{x, x} u)(t, x) - \\frac{(\\partial_x u^2)(t, x)}{2}\n",
    "=\n",
    "    \\nu (\\partial_{x, x} u)(t, x) - (\\partial_x u)(t, x) u(t, x),\n",
    "$$\n",
    "$$\n",
    "    u(t, 0) = u(t, S),\n",
    "\\qquad\n",
    "    (\\partial_x u)(t, 0) = (\\partial_x u)(t, S)\n",
    "$$\n",
    "for $(t, x) \\in [0,T] \\times [0, S]$.\n",
    "\n",
    "We want to approximate the map\n",
    "$$\n",
    "\\Phi(u(0, \\cdot)) = u(T, \\cdot).\n",
    "$$\n",
    "\n",
    "Problem parameters:  $T, S, \\nu \\in (0,\\infty)$ and distribution of initial value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d66e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "# from scipy.fft import fft, ifft, fftfreq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "import importlib\n",
    "import torch\n",
    "import openpyxl\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(1, '../1_Modules')\n",
    "\n",
    "# Importing the modules\n",
    "import random_function_generators\n",
    "import ode_methods\n",
    "import training\n",
    "import training_samples_generators\n",
    "import operator_learning_models\n",
    "import utils\n",
    "import burgers_classical_methods\n",
    "import evaluation_utils\n",
    "import documentation_utils\n",
    "import PDE_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading the modules\n",
    "importlib.reload(random_function_generators)\n",
    "importlib.reload(ode_methods)\n",
    "importlib.reload(training)\n",
    "importlib.reload(training_samples_generators)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(operator_learning_models)\n",
    "importlib.reload(burgers_classical_methods)\n",
    "importlib.reload(evaluation_utils)\n",
    "importlib.reload(documentation_utils)\n",
    "importlib.reload(PDE_operations)\n",
    "\n",
    "from random_function_generators import *\n",
    "from ode_methods import *\n",
    "from training import *\n",
    "from training_samples_generators import *\n",
    "from operator_learning_models import *\n",
    "from utils import *\n",
    "from burgers_classical_methods import *\n",
    "from evaluation_utils import *\n",
    "from documentation_utils import *\n",
    "from PDE_operations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = True\n",
    "\n",
    "#Problem setup periodic Burgers PDE in 1d\n",
    "###################################################\n",
    "T = 1.\n",
    "space_size = 2 * np.pi\n",
    "laplace_factor = 0.1\n",
    "dim = 1 # Dimension can only be 1 for Burgers\n",
    "\n",
    "# initial value\n",
    "var = 1000\n",
    "decay_rate = 3.\n",
    "offset = np.power(var, 1/decay_rate)\n",
    "inner_decay = 2.\n",
    "initial_value_generator = RandnFourierSeriesGenerator([var, decay_rate, offset, inner_decay, space_size, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3564dfafc3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretization operations\n",
    "x_values = x_values_periodic\n",
    "reduce_dimension = reduce_dimension_periodic\n",
    "get_higher_nr_spacediscr = get_higher_nr_spacediscr_periodic\n",
    "create_boundary_values = create_boundary_values_periodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantities derived from setup\n",
    "###################################################\n",
    "# Name of the PDE\n",
    "pde_name = f\"Burgers_T{T}_S{space_size}_nu{laplace_factor}_var{var}_decay{decay_rate}_offset{offset}_innerdecay{inner_decay}\"\n",
    "\n",
    "#Create folder for all outputs\n",
    "output_folder_dir = create_output_folder(pde_name)\n",
    "\n",
    "#Prepare df to store data\n",
    "methods_data = pd.DataFrame(columns=[\"nr_params\", \"training_time\", \"test_time\", \"L2_error\", \"done_trainsteps\", \"learning_rate_history\", \"batch_size_history\"])\n",
    "methods = {}\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3666bd",
   "metadata": {},
   "source": [
    "### Create Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea223bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data = True\n",
    "data_load_folder = \"2023-06-29 21h55m Code output/\"\n",
    "\n",
    "#Nr of input points allowed to be used by methods\n",
    "nr_spacediscr = 128\n",
    "\n",
    "#Method for reference solutions for training of models\n",
    "reference_algorithm = lambda initial_values, nr_timesteps: burgers_spectral_freqsp_lirk(initial_values, T, laplace_factor, space_size, nr_timesteps)\n",
    "\n",
    "# Train set parameters\n",
    "train_space_resolution_step = 4 if test_run else 4\n",
    "train_nr_timesteps = 1000 if test_run else 1000\n",
    "nr_train_samples = 2**18 if test_run else 2**18\n",
    "nr_validation_samples = 2**14 if test_run else 2**14\n",
    "\n",
    "# Test set parameters\n",
    "test_space_resolution_step = 8 if test_run else 8\n",
    "test_nr_timesteps = 1500 if test_run else 1500\n",
    "nr_test_samples = 2**14 if test_run else 2**14\n",
    "\n",
    "only_save_rough = True\n",
    "\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "parameters = {\n",
    "    'T': T,\n",
    "    'space_size': space_size,\n",
    "    'laplace_factor': laplace_factor,\n",
    "    'var': var,\n",
    "    'decay_rate': decay_rate,\n",
    "    'offset': offset,\n",
    "    'inner_decay': inner_decay,\n",
    "    'nr_spacediscr': nr_spacediscr,\n",
    "    'train_space_resolution_step': train_space_resolution_step,\n",
    "    'train_nr_timesteps': train_nr_timesteps,\n",
    "    'nr_train_samples': nr_train_samples,\n",
    "    'nr_validation_samples': nr_validation_samples,\n",
    "    'test_space_resolution_step': test_space_resolution_step,\n",
    "    'nr_test_samples': nr_test_samples,\n",
    "    'test_nr_timesteps': test_nr_timesteps,\n",
    "    'reference_algorithm': reference_algorithm.__name__,\n",
    "    'only_save_rough': only_save_rough\n",
    "}\n",
    "\n",
    "# save parametesr\n",
    "with open(output_folder_dir + 'train_test_parameters.json', 'w') as fp:\n",
    "    json.dump(parameters, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f546517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce train and test data\n",
    "train_nr_spacediscr = get_higher_nr_spacediscr(nr_spacediscr, train_space_resolution_step)\n",
    "test_nr_spacediscr = get_higher_nr_spacediscr(nr_spacediscr, test_space_resolution_step)\n",
    "\n",
    "print(\"Generating train samples\")\n",
    "train_initial_values_fine, train_ref_sol_fine, train_initial_values_rough, train_ref_sol_rough = (\n",
    "    get_data(\n",
    "        initial_value_generator, reference_algorithm, \n",
    "        nr_train_samples, train_nr_spacediscr, train_nr_timesteps, \n",
    "        reduce_dimension, train_space_resolution_step, 'train', \n",
    "        output_folder_dir, generate_data, data_load_folder, parameters, only_save_rough\n",
    "    ))\n",
    "training_samples_generator = TrainingSamplesGeneratorFromSolutions(train_initial_values_rough, train_ref_sol_rough)\n",
    "\n",
    "print(\"Generating validation samples\")\n",
    "validation_initial_values_fine, validation_ref_sol_fine, validation_initial_values_rough, validation_ref_sol_rough = (\n",
    "    get_data(\n",
    "        initial_value_generator, reference_algorithm, \n",
    "        nr_validation_samples, test_nr_spacediscr, test_nr_timesteps, \n",
    "        reduce_dimension, test_space_resolution_step, 'validate', \n",
    "        output_folder_dir, generate_data, data_load_folder, parameters, only_save_rough\n",
    "    ))\n",
    "\n",
    "print(\"Generating test samples\")\n",
    "test_initial_values_fine, test_ref_sol_fine, test_initial_values_rough, test_ref_sol_rough = (\n",
    "    get_data(\n",
    "        initial_value_generator, reference_algorithm, \n",
    "        nr_test_samples, test_nr_spacediscr, test_nr_timesteps, \n",
    "        reduce_dimension, test_space_resolution_step, 'test', \n",
    "        output_folder_dir, generate_data, data_load_folder, parameters, only_save_rough\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot some reference solutions \n",
    "plot_reference_solutions(train_initial_values_rough, train_ref_sol_rough, 4, dim, x_values, space_size, pde_name, output_folder_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f018a",
   "metadata": {},
   "source": [
    "# Create models and methods to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691ce97635fd6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer_class = torch.optim.Adam\n",
    "# Loss function\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5729072",
   "metadata": {},
   "source": [
    "### Operator learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparams\n",
    "OL_training_kwargs = {\n",
    "    \"max_trainsteps\": 100000 if test_run else 100000,\n",
    "    \"initial_batchsize\": 2**9 if test_run else 2**10,\n",
    "    \"max_batchsize\":2**9 if test_run else 2**10,\n",
    "    \"output_steps\": 200 if test_run else 200,\n",
    "    \"eval_steps\": 400 if test_run else 400,\n",
    "    \"improvement_tolerance\": 0.96 if test_run else 0.96,\n",
    "    \"initial_lr\": 0.001\n",
    "}\n",
    "nr_runs = 1 if test_run else 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0710da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN models\n",
    "ann_foldername = output_folder_dir + \"Results_ANN\"\n",
    "\n",
    "#ANN Parameters [layer_dims]\n",
    "list_ann_params = [\n",
    "    [[nr_spacediscr, 2**8, 2**9, 2**8, nr_spacediscr]],\n",
    "    [[nr_spacediscr, 2**8, 2**10, 2**10, 2**8, nr_spacediscr]],\n",
    "    [[nr_spacediscr, 2**9, 2**11, 2**11, 2**9, nr_spacediscr]],\n",
    "    [[nr_spacediscr, 2**10, 2**12, 2**13, 2**12, 2**10, nr_spacediscr]]\n",
    "]\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = ANNModel, \n",
    "    list_params = list_ann_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=None,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = ann_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ff69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN perdiodic models\n",
    "CNNPeriodic_foldername = output_folder_dir + \"Results_Periodic CNN\"\n",
    "\n",
    "#CNN Parameters [channel_dims, kernel_sizes, dim]\n",
    "list_cnn_periodic_params = [\n",
    "    [[1, 50, 50, 1],[51, 51, 51], 1],\n",
    "    [[1, 50, 50, 50, 1],[41, 41, 41, 41], 1],\n",
    "    [[1, 50, 100, 100, 50, 1], [31, 31, 31, 31, 31], 1],\n",
    "    [[1, 100, 200, 200, 100, 100, 1], [31, 31, 31, 31, 31, 31], 1]\n",
    "]\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = CNNPeriodicnDModel, \n",
    "    list_params = list_cnn_periodic_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=None,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = CNNPeriodic_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef74fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN simple enc dec models\n",
    "CNNEncDec_foldername = output_folder_dir + \"Results_Enc-Dec CNN\"\n",
    "\n",
    "#CNN Parameters [channel_dims, kernel_sizes, dim]\n",
    "list_cnn_enc_dec_params = [\n",
    "    [[1, 8, 32, 64],[2, 4, 2], 1],\n",
    "    [[1, 8, 32, 64, 128], [4, 2, 2, 4], 1],\n",
    "    [[1, 8, 32, 64, 128, 256], [4, 2, 2, 4, 2], 1],\n",
    "    [[1, 8, 32, 64, 128, 256, 512, 512],[2, 2, 2, 2, 2, 2, 2], 1]\n",
    "]\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = CNNEncDec, \n",
    "    list_params = list_cnn_enc_dec_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=None,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = CNNEncDec_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNO models\n",
    "FNO_foldername = output_folder_dir + \"Results_FNO\"\n",
    "\n",
    "#list is [#modes, width, depth, dim]\n",
    "list_fno_params = [\n",
    "    [8, 20, 4, 1],\n",
    "    [16, 20, 4, 1],\n",
    "    [16, 30, 4, 1],\n",
    "    [16, 30, 5, 1]\n",
    "]\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = FNOnDModel, \n",
    "    list_params = list_fno_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=None,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = FNO_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepONets\n",
    "DeepONet_foldername = output_folder_dir + \"Results_DeepONet\"\n",
    "\n",
    "DeepONet_space_grid = np.transpose(x_values(nr_spacediscr, space_size)) # Need shape (nr_spacediscr, dim)\n",
    "\n",
    "# DeepOnet Parameters [trunk_architecture, branch_architecture, eval_points]\n",
    "list_deeponet_params = [\n",
    "    [[nr_spacediscr, 200, 200, 100],[1, 50, 100], DeepONet_space_grid],\n",
    "    [[nr_spacediscr, 200, 200, 300],[1, 50, 100, 300], DeepONet_space_grid],\n",
    "    [[nr_spacediscr, 300, 600, 1000, 500],[1, 100, 300, 500], DeepONet_space_grid],\n",
    "    [[nr_spacediscr, 300, 600, 2000, 1000],[1, 200, 500, 1000], DeepONet_space_grid]\n",
    "]\n",
    "\n",
    "\n",
    "create_and_train_models(\n",
    "    modelclass = DeepONet, \n",
    "    list_params = list_deeponet_params,\n",
    "    training_samples_generator = training_samples_generator,\n",
    "    optimizer_class = optimizer_class,\n",
    "    loss_fn = loss_fn,\n",
    "    training_kwargs=OL_training_kwargs,\n",
    "    lr_search_params=None,\n",
    "    nr_runs = nr_runs,\n",
    "    methods = methods,\n",
    "    methods_data = methods_data,\n",
    "    foldername = DeepONet_foldername,\n",
    "    test_input_values = test_initial_values_rough,\n",
    "    test_ref_sol = test_ref_sol_rough,\n",
    "    validation_input_values = validation_initial_values_rough,\n",
    "    validation_ref_sol = validation_ref_sol_rough,\n",
    "    pde_name = pde_name,\n",
    "    local_learning_rates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977d2b5",
   "metadata": {},
   "source": [
    "### Classical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b49bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretization parameters\n",
    "nr_timesteps_fdm = [5, 10, 15, 20] # [1, 5, 7, 8, 9, 10, 15, 20] # , 30, 40, 70, 100, 200, 300, 400, 500, 1000, 1500, 2000]\n",
    "nr_timesteps_fem = [5, 10, 15, 20] # ,, 100]\n",
    "nr_timesteps_spe = [5, 10, 15, 20] # , 50, 60, 70, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "#Create all methods for the correponding timesteps\n",
    "# FDM (I do not evaluate the euler method at the moment)\n",
    "for nr_timesteps in nr_timesteps_fdm:\n",
    "    for conservative in [True]: #[True, False]:\n",
    "        for v in [2]: #range(3):\n",
    "            # name = \"FDM (%i CN tsps, conservative:%i, v:%i)\"% (nr_timesteps, conservative, v)\n",
    "            name = f\"FDM ({nr_timesteps} Crank Nicolson timesteps)\"\n",
    "            methods[name] = lambda initial_values_rough, nr_timesteps=nr_timesteps, v=v, conservative=conservative: burger_fdm_lirk(initial_values_rough, T, laplace_factor, space_size, nr_timesteps, v, conservative)\n",
    "            methods_data.at[name, \"training_time\"] = 0\n",
    "\n",
    "# FEM\n",
    "for nr_timesteps in nr_timesteps_fem:\n",
    "    # name = \"FEM (%i CN tsps)\" % nr_timesteps\n",
    "    name = f\"FEM ({nr_timesteps} Crank Nicolson timesteps)\"\n",
    "    methods[name] = lambda initial_values_rough, nr_timesteps=nr_timesteps: burger_fem_lirk(initial_values_rough, T, laplace_factor, space_size, nr_timesteps)\n",
    "    methods_data.at[name, \"training_time\"] = 0\n",
    "\n",
    "# Spectral eval (I do not evaluate the euler method at the moment)\n",
    "for nr_timesteps in nr_timesteps_spe:\n",
    "    for conservative in [True]: #[True, False]:\n",
    "        # name = \"Spectral (%i CN tsps, conservative:%i)\" % (nr_timesteps, conservative)\n",
    "        name = f\"Spectral ({nr_timesteps} Crank Nicolson timesteps)\"\n",
    "        methods[name] = lambda initial_values_rough, nr_timesteps=nr_timesteps, conservative=conservative: burgers_spectral_freqsp_lirk(initial_values_rough, T, laplace_factor, space_size, nr_timesteps, conservative)\n",
    "        methods_data.at[name, \"training_time\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1315749fb2fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.insert(1, '../3_ADANNs/1_ADANN_Modules')\n",
    "\n",
    "# from ADANNs import *\n",
    "\n",
    "# #Create all methods for the correponding timesteps\n",
    "# # FDM (I do not evaluate the euler method at the moment)\n",
    "# for nr_timesteps in nr_timesteps_fdm:\n",
    "#     for v in [2]: \n",
    "#         name = f\"ADANNs (FDM, {nr_timesteps} Crank-Nicolson time steps)\"\n",
    "#         methods[name] = SecondOrderLirkFDMPeriodicBurgersAdannBasemodel_learnFirstOrder(T, laplace_factor, space_size, nr_spacediscr, nr_timesteps, v).to(device)\n",
    "#         methods_data.at[name, \"training_time\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b165bfb",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3a789-d277-43b3-b622-12e056fccae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all the methods and create plots\n",
    "nr_of_eval_runs = 1000 if test_run else 1000\n",
    "plot_histogram = False if test_run else True\n",
    "\n",
    "method_categories = [\"ANN\", \"Periodic CNN\", \"Enc.-Dec. CNN\", \"FNO\", \"DeepONet\", \"FDM\", \"FEM\", \"Spectral\", \"ADANNs\"]\n",
    "space_grid = x_values(nr_spacediscr, space_size)\n",
    "\n",
    "evaluate_and_plot(methods, \n",
    "                  methods_data, \n",
    "                  method_categories, \n",
    "                  test_initial_values_rough, \n",
    "                  test_ref_sol_rough, \n",
    "                  space_grid, \n",
    "                  space_size, \n",
    "                  output_folder_dir, \n",
    "                  pde_name, \n",
    "                  dim=dim, \n",
    "                  nr_of_eval_runs=nr_of_eval_runs, \n",
    "                  plot_histogram=plot_histogram,\n",
    "                  legend_loc=None,\n",
    "                  nr_of_plots=1 if test_run else 3\n",
    "                  )\n",
    "\n",
    "#Save all the data in an Excel sheet\n",
    "local_vars = locals()\n",
    "params_dict = {k: [v] for k, v in local_vars.items() if isinstance(v, (int, str, float)) and k[0] != '_'}\n",
    "save_excel_sheet(methods_data, params_dict, output_folder_dir + f\"Results_{pde_name}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729c04d84d4a325",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_error_vs_comptime_plot(method_categories, output_folder_dir, pde_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298290c393e00293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_PDE_survey",
   "language": "python",
   "name": "venv_pde_survey"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
